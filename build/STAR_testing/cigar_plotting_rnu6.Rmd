---
title: "Benchmarking STAR Testing - Complete Sample "
author: "Samantha Sevilla"
date: "3/4/2022"
output: html_document
editor_options: 
  chunk_output_type: console
---
## Background

In this benchmarking experiment, STAR was compared to NOVOAlign, currently utilized in our iCLIP pipeline. STAR version 2.7.8a was used (https://github.com/alexdobin/STAR/releases).

For each read, an alignment was assessed for any gaps, with two possible scenarios:

1) alignment---gap---alignment

2) alignment---gap--insertion/deletion---alignment

For all reads that match outcome #1, reads were counts. For gaps with reads larger than 100, overhang and parent were assigned to the alignments as follows:

3) overhang: the smaller length of the two alignments

4) parent: the larger length of the two alignments

Ratios were calculated for each read that met this criterion. For example #5 would have a ratio of 2/70, #6 would have a ratio of 2/70, and #7 would not be included due to the gap being <100.

5) alignment1(N=2)---gap(N=100)---alignment2(N=70)

6) alignment3(N=70)---gap(N=100)---alignment4(N=2)

7) alignment3(N=70)---gap(N=10)---alignment4(N=2)

For reads with N>2 gaps, each gap was assessed individually. For example #8 would have 2 gaps assessed, example #9 would have 3 gaps assessed and example #10 would have 1 gap assessed as gap2 does not meet the 100 threshold requirement

8) alignment1(N=2)---gap1(N=100)---alignment2(N=70)---gap2(N=100)---alignment4(N=2)

9) alignment3(N=70)---gap1(N=100)---alignment4(N=2)--gap2(N=100)---alignment4(N=2)--gap3(N=100)---alignment4(N=2)

10) alignment3(N=70)---gap1(N=100)---alignment4(N=2)--gap2(N=50)---alignment4(N=2)

```{r echo=FALSE, include=FALSE}
library(knitr)
library(tidyr)
library(ggplot2)
library(dplyr)
library(DT)
```

```{r setup, include=FALSE}
parent_dir="~/../../Volumes/RBL_NCI/Wolin/mES_fclip_1_YL_012122/alignment_analysis/star/"
variations_file=paste0(parent_dir,"docs/STAR_variations.txt")
align_dir=paste0(parent_dir,"output/rnu_sample/align/")
sample_list=c("2e","ClipSeqTools_v1","novo_original","2e_git","clipv1_git","2e_double",
              "clipv1_double","2e_lowerq")
```

# Variations Summary
```{r echo=FALSE}
#read in variation file
variations_summary=read.csv(variations_file,sep="\t")
colnames(variations_summary) = c("Alignment Flag", "Description",
                                 "Default", 
                                 "star_1a", "star_1b", "star_1c",
                                 "star_2a", "star_2b", "star_2c", "star_2d", "star_2e", 
                                 "star_2f", "star_2g", "star_2h","star_2i","star_2j",
                                 "star_encode1", "star_encode2",
                                 "star_clipseqtools_v1","star_clipseqtools_v2",
                                 "novo_test5", "novo_1", "novo_2", "novo_3",
                                 "2e_git","clipv1_git","2e_double","clipv1_double","2e_lowerq")

#split for definitions only
kable(variations_summary[c(1:18),1:2])

#split for variations star
kable(variations_summary[c(1:18),c(1,11,14,15,16,19,20)])

```

# Alignment
Alignment statistics were generated for each version type, including a comparison between the total number of reads uniquely mapped to those that were unmapped, and the total number of reads unique mapped and those that were multimapped.

```{r echo=FALSE}
#read in df
align_df=read.csv(paste0(align_dir,"alignment_stats.txt"),sep=",",col.names=c("total","mapped","unmapped","unique","mm",""))
align_df=align_df[,c(-1,-6)]

#plot of unique map to unmapped
tmp_df=data.frame(rownames(align_df))
for (rowid in rownames(align_df)){
  tmp_df[nrow(tmp_df)+1,"version_id"]=rowid
  tmp_df[nrow(tmp_df),"type"]="uniquely mapped"
  tmp_df[nrow(tmp_df),"read_count"]=align_df[rowid,"unique"]
  
  tmp_df[nrow(tmp_df)+1,"version_id"]=rowid
  tmp_df[nrow(tmp_df),"type"]="unmapped"
  tmp_df[nrow(tmp_df),"read_count"]=align_df[rowid,"unmapped"]
}
tmp_df=tmp_df[,-1]
tmp_df=tmp_df[complete.cases(tmp_df),]

#print plot of reads
p = ggplot(tmp_df,aes(x=version_id,y=read_count,fill=type))+
    geom_bar(position='stack', stat='identity') +
    #facet_wrap(~gap_count, scales = "free_y") +
    xlab("Version of Testing") +
    ylab("N of Reads") +
    scale_x_discrete(guide = guide_axis(angle = 90)) +
    ggtitle("Number of reads uniquely mapped versus unmapped")

p = p + theme(legend.position="top")
print(p)

#plot of unique to mm 
tmp_df=data.frame(rownames(align_df))
for (rowid in rownames(align_df)){
  tmp_df[nrow(tmp_df)+1,"version_id"]=rowid
  tmp_df[nrow(tmp_df),"type"]="uniquely mapped"
  tmp_df[nrow(tmp_df),"read_count"]=align_df[rowid,"unique"]
  
  tmp_df[nrow(tmp_df)+1,"version_id"]=rowid
  tmp_df[nrow(tmp_df),"type"]="multimapped"
  tmp_df[nrow(tmp_df),"read_count"]=align_df[rowid,"mm"]
}
tmp_df=tmp_df[,-1]
tmp_df=tmp_df[complete.cases(tmp_df),]

#print plot of reads
p = ggplot(tmp_df,aes(x=version_id,y=read_count,fill=type))+
    geom_bar(position='stack', stat='identity') +
    #facet_wrap(~gap_count, scales = "free_y") +
    xlab("Version of Testing") +
    ylab("N of Reads") +
    scale_x_discrete(guide = guide_axis(angle = 90)) +
    ggtitle("Number of reads uniquely mapped versus multimapped")

p = p + theme(legend.position="top")
print(p)
```

# Number of Gaps
Reads were found to have a variable number of gaps. A total count of these gaps were recorded regardless of length. Then, these were subset for only reads with any gap greater than 100 bp in length. The graphic below shows each version (X) by the total number of reads (Y), stratified by the N of gaps found (1,2,3). The bars are split by the gap_subcount, which is the number of gaps within the read that is greater than 100 bp. For example, in reads for 2e in which there was 1 gap found, approximately 25% of those reads had no gaps (gap_subcount=0) that were greater than the minimum threshold of 100 (salmon colored) and approxmiately 75% of those reads were greater than 100 (gree colored). The second graphic subsets for only reads that included gaps >100bp.

```{r echo=FALSE}
counter=1
for (sample_id in sample_list){
  #import gap count file
  tmp_count=read.csv(paste0(cigar_dir,sample_id,"_gap_counts.txt"),sep=",",col.names=c("read_count","gap_count","gap_subcount","version_id"))
  tmp_agg=aggregate(read_count~gap_count+gap_subcount, data=tmp_count,FUN=sum)
  tmp_agg$version_id=sample_id
  
  #if the gap count is only 2
  if (nrow(tmp_agg)==2){
    tmp_agg[3,]=c("3",0,sample_id)
  }
  
  if (counter==1){
    gap_count_df=tmp_agg
  } else{
    gap_count_df=rbind(gap_count_df,tmp_agg)
  }
  counter=2

  remove(tmp_count,tmp_agg)
}

#adj str
gap_count_df$gap_count=factor(gap_count_df$gap_count)
gap_count_df$gap_subcount=factor(gap_count_df$gap_subcount)
gap_count_df$read_count=as.numeric(gap_count_df$read_count)

#print plot of gaps
p = ggplot(gap_count_df,aes(x=version_id,y=read_count,fill=gap_subcount))+
    geom_bar(position='stack', stat='identity') +
    facet_wrap(~gap_count, scales = "free_y") +
    xlab("Version of Testing") +
    ylab("N of Occurances") +
    scale_x_discrete(guide = guide_axis(angle = 90)) +
    ggtitle("Number of reads with N gaps per variable,\ncolored by number of gaps (gap_subcount) > 100bp")

p = p + theme(legend.position="top")
print(p)


#print plot of gaps >100
tmp_df=subset(gap_count_df,gap_subcount!=0)

#print plot of gaps
p = ggplot(tmp_df,aes(x=version_id,y=read_count,fill=gap_subcount))+
    geom_bar(position='stack', stat='identity') +
    facet_wrap(~gap_count, scales = "free_y") +
    xlab("Version of Testing") +
    ylab("N of Occurances") +
    scale_x_discrete(guide = guide_axis(angle = 90)) +
    ggtitle("Number of reads with N gaps per variable >100bp")

p = p + theme(legend.position="top")
print(p)
```

The data table includes counts of all reads with at least one gap > 100 bp.

```{r echo=FALSE}
#sub for gaps >100 and aggregate df
tmp_df=subset(gap_count_df,gap_subcount!=0)
tmp_df=aggregate(read_count~gap_count+version_id,data=tmp_df,FUN=sum)

#add gap_count=3 to ClipSeqTools
tmp_df[nrow(tmp_df)+1,]=c(3,"ClipSeqTools_v1",0)

#create table
output_df=data.frame(unique(tmp_df$version_id))
output_df$gap_1=as.numeric(subset(tmp_df,gap_count==1)$read_count)
output_df$gap_2=as.numeric(subset(tmp_df,gap_count==2)$read_count)
output_df$gap_3=as.numeric(subset(tmp_df,gap_count==3)$read_count)
rownames(output_df)=output_df$unique.tmp_df.version_id.
output_df=output_df[,c(2:4)]

#fix gap3 error
output_df[nrow(output_df),"gap_3"]=output_df[nrow(output_df)-1,"gap_3"]
output_df[nrow(output_df)-1,"gap_3"]=0
output_df$gap_total=rowSums(output_df)

#formatting
output_df$gap_1=format(output_df$gap_1, big.mark=",")
output_df$gap_2=format(output_df$gap_2, big.mark=",")
output_df$gap_3=format(output_df$gap_3, big.mark=",")
output_df$gap_total=format(output_df$gap_total, big.mark=",")

#print table
DT::datatable(output_df)
```

# Gap Features
```{r echo=FALSE}
counter=1
for (sample_id in sample_list){
  #import gap count file
  tmp_count=read.csv(paste0(cigar_dir,sample_id,"_gap_analysis.txt"),sep=",",
                     col.names=c("count","ratio","length_of_gap","overhang_length","parent_length", "id"))
  tmp_count$id=sample_id
  
  if (counter==1){
    counts_df=tmp_count
  } else{
    counts_df=rbind(counts_df,tmp_count)
  }
  counter=2

  remove(tmp_count)
}

#convert to numeric
counts_df$count=as.numeric(counts_df$count)
counts_df$length_of_gap=as.numeric(counts_df$length_of_gap)
  
#sort data by overhang
counts_df=counts_df[order(counts_df$overhang_length),]
  
#fix factor levels, order
counts_df$overhang_length=factor(counts_df$overhang_length, 
                                 levels=c(as.character(sort(as.numeric(unique(counts_df$overhang_length))))))

```

```{r include=FALSE}
# set up cut-off values 
breaks <- c(0,1000,10000,20000,30000,40000,50000,100000,1000000000)
    
# specify interval/bin labels
tags <- c("[0-1,000)","[1,000-100,00)", "[10,000-20,000)", "[20,000-30,000)", "[30,000-40,000)", "[40,000-50,000)",
          "[50,000-100,000)","[100,000<)")
    
# bucketing values into bins
counts_df$gap_group <- cut(counts_df$length_of_gap, 
                    breaks=breaks, 
                    include.lowest=TRUE, 
                    right=FALSE, 
                    labels=tags)

#fix factor levels, order
counts_df$gap_group=factor(counts_df$gap_group, 
                                 levels=c(tags))
```

## Summary Tables
Summary table of alignment variation by the length of overhang or length of gap. Values indicate the number of times this feature was observed. Only gaps >100bp, with overhang/parent ratios <.20 are considered.

```{r echo=FALSE, warning=FALSE, message=FALSE}
#subset for overhangs
counts_sub_df=subset(counts_df,ratio<0.2)

#counts of overhang length
summary_df=data.frame()
for (version_id in unique(counts_sub_df$id)){
  tmp_df=subset(counts_sub_df,id==version_id)
  
  summary_df[nrow(summary_df)+1,"id"]=version_id
  for (overhang_val in unique(tmp_df$overhang_length)){
    tmp_df2=subset(tmp_df,overhang_length==overhang_val)
    summary_df[nrow(summary_df),paste0(overhang_val)]=sum(tmp_df2$count)
  }
}
col_list=as.character(sort(as.numeric(as.character(unique(counts_sub_df$overhang_length)))))

#convert NAs
summary_df = summary_df %>% 
  select(c("id",col_list)) %>% 
  replace(is.na(.), 0)

summary_df$totals=rowSums(summary_df[,2:ncol(summary_df)])
summary_df <-summary_df[order(summary_df$id),]
DT::datatable(summary_df)

#counts of gap length
summary_df=data.frame()
for (version_id in unique(counts_df$id)){
  tmp_df=subset(counts_df,id==version_id)
  
  summary_df[nrow(summary_df)+1,"id"]=version_id
  
  for (gap_id in unique(tmp_df$gap_group)){
    tmp_df2=subset(tmp_df,gap_group==gap_id)
    summary_df[nrow(summary_df),paste0(gap_id)]=sum(tmp_df2$count)
  }
}

summary_df = summary_df %>% 
  select(c("id",all_of(tags))) %>% 
  replace(is.na(.), 0)
summary_df <-summary_df[order(summary_df$id),]
DT::datatable(summary_df)
```

## Summary Plots
### Overhang length
Summary plot of ratios of overhang/parent alignment (see above for definitions) by the number of times they occur within the alignment variation. Only ratios under 0.2 are shown.

```{r echo=FALSE}
tmp_df=subset(counts_df,ratio<.2)

#plot data
p = ggplot(tmp_df,aes(x=ratio,y=count,fill=overhang_length))+ 
    geom_bar(position='stack', stat='identity') +
    facet_wrap(~id) +
    xlab("Ratio of overhang/parent") +
    ylab("N of Occurances") 

p = p + theme(legend.position="top")
print(p)
```

### Gap length
Summary plot of ratios of overhang/parent by the number of times they occur within the alignment variation, colored by the length of the gap observed. Only ratios under 0.2 are shown.
```{r echo=FALSE}
#plot data
p = ggplot(tmp_df,aes(x=ratio,y=count,fill=gap_group))+ 
    geom_bar(position='stack', stat='identity') +
    facet_grid(id~gap_group) +
    xlab("Ratio of overhang/parent") +
    ylab("N of Occurances")


p = p + theme(legend.position="top", strip.text.x = element_text(angle = 90), strip.text.y = element_text(angle = 0),
              axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5))
print(p)
```

# Conclusion
Based on the read distribution of mapping (uniquely mapped vs unmapped, uniquely mapped vs multimapped), reads that have a low gap number (N<3), reads that have a higher ratio of overhang to parent (ratio >0.2), and gap length (gaps <100,000) the best performing parameters include ClipSeqTools_v1, ClipSeqTools_v2, and 2e.