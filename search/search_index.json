{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"The iCLIP pipeline was developed in support of NIH RNA Biology Laboratory (RBL) . It has been developed and tested solely on NIH HPC Biowulf .","title":"Background"},{"location":"iCLIP/getting-started/","text":"Overview \u00b6 The iCLIP github repository is stored locally, and will be used for project deployment. Multiple projects can be deployed from this one point simultaneously, without concern. 1. Getting Started \u00b6 1.1 Introduction The iCLIP Pipelie beings with raw FASTQ files and performs demultiplexing, adaptor removal, and trimming, as designated by the user. Alignment is then performed using STAR , followed by deduplication. Peaks are then called, where both unique and multimapped read counts are identified. Peaks are then collapsed, annotated, and summarized into reports. If designated either MANORM or DIFFBIND is performed on peak findings. QC reports are also generated with each project. The following are sub-commands used within iCLIP: initialize: initalize the pipeline dryrun: predict the binding of peptides to any MHC molecule cluster: execute the pipeline on the Biowulf HPC local: execute a local, interactive, session git: execute GitHub actions unlock: unlock directory DAG: create DAG report report: create SNAKEMAKE report 1.2 Setup Dependencies \u00b6 iCLIP has several dependencies listed below. These dependencies can be installed by a sysadmin. All dependencies will be automatically loaded if running from Biowulf. bedtools: \"bedtools/2.29.2\" bowtie2: \"bowtie/2-2.3.4\" fastq_screen: \"fastq_screen/0.14.0\" fastqc: \"fastqc/0.11.9\" manorm: \"manorm/1.1.4\" multiqc: \"multiqc/1.9\" perl: \"perl/5.24.3\" python: \"python/3.8\" R: \"R/4.0\" samtools: \"samtools/1.11\" star: \"STAR/2.7.8a\" subread: \"subread/2.0.1\" ultraplex: \"ultraplex/1.2.5\" umitools: \"umitools/1.1.1\" 1.3 Login to the cluster \u00b6 iCLIP has been exclusively tested on Biowulf HPC. Login to the cluster's head node and move into the pipeline location. # ssh into cluster's head node ssh -Y $USER@biowulf.nih.gov # move the iCLIP dir cd /data/RBL_NCI/Pipelines/iCLIP/[version number] 1.4 Load an interactive session \u00b6 An interactive session should be started before performing any of the pipeline sub-commands, even if the pipeline is to be executed on the cluster. # Grab an interactive node srun -N 1 -n 1 --time=12:00:00 -p interactive --mem=8gb --cpus-per-task=4 --pty bash","title":"1. Getting Started"},{"location":"iCLIP/getting-started/#overview","text":"The iCLIP github repository is stored locally, and will be used for project deployment. Multiple projects can be deployed from this one point simultaneously, without concern.","title":"Overview"},{"location":"iCLIP/getting-started/#1-getting-started","text":"1.1 Introduction The iCLIP Pipelie beings with raw FASTQ files and performs demultiplexing, adaptor removal, and trimming, as designated by the user. Alignment is then performed using STAR , followed by deduplication. Peaks are then called, where both unique and multimapped read counts are identified. Peaks are then collapsed, annotated, and summarized into reports. If designated either MANORM or DIFFBIND is performed on peak findings. QC reports are also generated with each project. The following are sub-commands used within iCLIP: initialize: initalize the pipeline dryrun: predict the binding of peptides to any MHC molecule cluster: execute the pipeline on the Biowulf HPC local: execute a local, interactive, session git: execute GitHub actions unlock: unlock directory DAG: create DAG report report: create SNAKEMAKE report","title":"1. Getting Started"},{"location":"iCLIP/getting-started/#12-setup-dependencies","text":"iCLIP has several dependencies listed below. These dependencies can be installed by a sysadmin. All dependencies will be automatically loaded if running from Biowulf. bedtools: \"bedtools/2.29.2\" bowtie2: \"bowtie/2-2.3.4\" fastq_screen: \"fastq_screen/0.14.0\" fastqc: \"fastqc/0.11.9\" manorm: \"manorm/1.1.4\" multiqc: \"multiqc/1.9\" perl: \"perl/5.24.3\" python: \"python/3.8\" R: \"R/4.0\" samtools: \"samtools/1.11\" star: \"STAR/2.7.8a\" subread: \"subread/2.0.1\" ultraplex: \"ultraplex/1.2.5\" umitools: \"umitools/1.1.1\"","title":"1.2 Setup Dependencies"},{"location":"iCLIP/getting-started/#13-login-to-the-cluster","text":"iCLIP has been exclusively tested on Biowulf HPC. Login to the cluster's head node and move into the pipeline location. # ssh into cluster's head node ssh -Y $USER@biowulf.nih.gov # move the iCLIP dir cd /data/RBL_NCI/Pipelines/iCLIP/[version number]","title":"1.3 Login to the cluster"},{"location":"iCLIP/getting-started/#14-load-an-interactive-session","text":"An interactive session should be started before performing any of the pipeline sub-commands, even if the pipeline is to be executed on the cluster. # Grab an interactive node srun -N 1 -n 1 --time=12:00:00 -p interactive --mem=8gb --cpus-per-task=4 --pty bash","title":"1.4 Load an interactive session"},{"location":"iCLIP/output/","text":"4. Expected Outputs \u00b6 The following directories are created under the output_directory: 01_preprocess: this directory includes FASTQ and alignment files 01_fastq: FASTQ files, demultiplexed 02_alignment: aligned, indexed, and sorted, alignment files 02_bam: this directory includes processed bam files 01_merged: unique and multi-mapped reads BAMS, sorted and indexed 03_dedup: all files in the 02_merged directory, deduplicated 03_peaks: this directory includes the bed and SAF files for the pipeline, sorted by: 01_bed: bed files sorted by all reads or unique reads 02_SAF: SAF files sorted by all reads or unique reads 03_counts: peak coutns for all and unique reads, split by unique and MM peaks 04_annotation: this directory includes the annotation files at a project and sample level, sorted by: 01_project: includes project level annotation information 02_peaks: includes annotation bed files, complete annotated peak text files final annotation report (HTML) and table (TXT) 05_demethod: this directory is only produced when MANORM or DIFFBIND is selected from DE_METHOD 01_input: this includes bed files for any samples being compared 02_analysis: this includes raw DE files (excel MANORM, text DIFFBIND) by comparison 03_report: this includes the final reports (HTML) by comparison qc: this directory includes the qc reports, sorted by: multiqc_report: this includes the fastqc results, as well as fastq screen results of each sample before and after filtering qc_report: this includes barcode and alignment information of each sample before and after filtering log: this includes log files [date of run]: the slurm output files of the pipeline sorted by pipeline start time; copies of config and manifest files used in this specific pipeline run; error reporting script STAR: star-related log output files","title":"4. Expected Output"},{"location":"iCLIP/output/#4-expected-outputs","text":"The following directories are created under the output_directory: 01_preprocess: this directory includes FASTQ and alignment files 01_fastq: FASTQ files, demultiplexed 02_alignment: aligned, indexed, and sorted, alignment files 02_bam: this directory includes processed bam files 01_merged: unique and multi-mapped reads BAMS, sorted and indexed 03_dedup: all files in the 02_merged directory, deduplicated 03_peaks: this directory includes the bed and SAF files for the pipeline, sorted by: 01_bed: bed files sorted by all reads or unique reads 02_SAF: SAF files sorted by all reads or unique reads 03_counts: peak coutns for all and unique reads, split by unique and MM peaks 04_annotation: this directory includes the annotation files at a project and sample level, sorted by: 01_project: includes project level annotation information 02_peaks: includes annotation bed files, complete annotated peak text files final annotation report (HTML) and table (TXT) 05_demethod: this directory is only produced when MANORM or DIFFBIND is selected from DE_METHOD 01_input: this includes bed files for any samples being compared 02_analysis: this includes raw DE files (excel MANORM, text DIFFBIND) by comparison 03_report: this includes the final reports (HTML) by comparison qc: this directory includes the qc reports, sorted by: multiqc_report: this includes the fastqc results, as well as fastq screen results of each sample before and after filtering qc_report: this includes barcode and alignment information of each sample before and after filtering log: this includes log files [date of run]: the slurm output files of the pipeline sorted by pipeline start time; copies of config and manifest files used in this specific pipeline run; error reporting script STAR: star-related log output files","title":"4. Expected Outputs"},{"location":"iCLIP/preparing-files/","text":"2. Preparing Files \u00b6 The pipeline is controlled through editing configuration and manifest files. Defaults are found in the /output/dir/config and /output/dir/manifest directories, after initialization. 2.1 Configs \u00b6 The configuration files control parameters and software of the pipeline. These files are listed below: annotation_config.txt cluster_config.yml fqscreen_rrna_config.conf fqscreen_species_config.conf index_config.yaml multiqc_config.yaml snakemake_config.yaml 2.1.1 Annotaiton Config (annotation_config.txt) \u00b6 The annotation config dictates the type and location of annotaiton files to use for each species (hg38 and mm10). The file must include the following headers: type AnnoType hg38_options hg38_selection hg38_Custom mm10_options mm10_selection mm10_Custom description rmsk_flag notes Status 2.1.2 Cluster Config (cluster_config.yml) \u00b6 The cluster configuration file dictates the resouces to be used during submission to Biowulf HPC. There are two differnt ways to control these parameters - first, to control the default settings, and second, to create or edit individual rules. These parameters should be edited with caution, after significant testing. 2.1.3 FASTQ Screen Config (fqscreen_rrna_config.conf and fqscreen_species_config.conf) \u00b6 The FASTQ sceren configuration files dictates the parameters used for FASTQ Screen. 2.1.4 Index Config (index_config.yaml) \u00b6 The index config is used to dictate what versions of reference index is used for each species (mm10, hg38). The structure of annotation is as follows: - organism: - std: '/path/to/index/' - spliceaware: - valuebp1: '/path/to/index1/' - valuebp2: '/path/to/index2/' 2.1.5 MultiQC Config (multiqc_config.yaml) \u00b6 The MultiQC screen configuration files control the parameters used for MultiQC. 2.1.6 Snakemake Config (snakemake_config.yaml) \u00b6 There are several groups of parameters that are editable for the user to control the various aspects of the pipeline. These are : Folders and Paths These parameters will include the input and ouput files of the pipeline, as well as list all manifest names. User parameters These parameters will control the pipeline features. These include thresholds and whether to perform processes. STAR parameters These parameters will control the STAR parameters for alignment. Modules, container parameters These parameters will control the version of tools used in the pipeline. 2.2 Preparing Manifests \u00b6 There are three manifests, two of which are required for all pipeliens and one that is only required if running a differential expression method. These files describe information on the samples and desired contrasts. The paths of these files are defined in the snakemake_config.yaml file. These files are: multiplexManifest sampleManifest contrastManifest 2.2.1 Multiplex Manifest (REQUIRED) \u00b6 This manifest will include information to map fastq files to their multiple sample ID. It includes the following column headers: file_name: the full file name of the multiplexed sample, which must be unique; example: 'test_1.fastq.gz' multiplex: the multiplexID associated the fastq file, which must be unique. These names must match the multiplex column of the sampleManifest. example: 'test_1' An example multplex_manifest.tsv file: file_name,multiplex test_1.fastq.gz,test_1 test_2.fastq.gz,test_2 2.2.2 Samples Manifest (REQUIRED) \u00b6 This manifest will include information to sample level information. It includes the following column headers: multiplex: the multiplexID associated with the fasta file, and will not be unique. These names must match the multiplex column of the multiplex_manifest.tsv file. example: 'SIM_iCLIP_S1' sample: the final sample name; this column must be unique. example: 'Ro_Clip' barcode: the barcode to identify multiplexed sample; this must be unique per each multiplex sample name but can repeat between multiplexid's. example: 'NNNTGGCNN' adaptor: the adaptor sequence, to be removed from sample; this may or may not be unique. example: 'AGATCGGAAGAGCGGTTCAG' group: groupings for samples, may or may not be unique values. example: 'CNTRL' An example sampleManifest file with multiplexing of one sample. Notice that the multiplexID test_1 is repeated, as Ro_Clip and Control_Clip are both found in the same fastq file, whereas test_2 is not multiplexed: multiplex,sample,group,barcode,adaptor test_1,Ro_Clip,CLIP,NNNTGGCNN,AGATCGGAAGAGCGGTTCAG test_1,Control_Clip,CNTRL,NNNCGGANN,AGATCGGAAGAGCGGTTCAG test_2,Ro_Clip2,CLIP,NNNCGTANN,AGATCGGAAGAGCGGTTCAG 2.2.3 Contrast Manifest (REQUIRED with DE_Method of MANORM or DIFFBIND) \u00b6 This manifest will include sample or group information to performed differential expresison comparisons (MANORM or DIFFBIND). The column requirements differ by DE method. - if MANORM: - sample: the sample name, identified in the samplesManifest [sample] column, of the sample to compare. example: 'Ro_Clip' - background: the background sample name, identified in the samplesManifest [sample] column, of the background to remove. example: 'Control_Clip' - if DIFFBIND: - sample: the sample group, identified in the samplesManifest [group] column, of the sample group to compare. example: 'CLIP' will include samples 'Ro_Clip' and 'Ro_Clip2' - background: the background group name, identified in the samplesManifest [group] column, of the background group to remove. example: 'CNTRL' will include sample 'Control_Clip' An example contrastManifest file for MANORM: sample,background Ro_Clip,Control_Clip An example contrastManifest file for DIFFBIND: group,background CLIP,CNTRL","title":"2. Preparing Files"},{"location":"iCLIP/preparing-files/#2-preparing-files","text":"The pipeline is controlled through editing configuration and manifest files. Defaults are found in the /output/dir/config and /output/dir/manifest directories, after initialization.","title":"2. Preparing Files"},{"location":"iCLIP/preparing-files/#21-configs","text":"The configuration files control parameters and software of the pipeline. These files are listed below: annotation_config.txt cluster_config.yml fqscreen_rrna_config.conf fqscreen_species_config.conf index_config.yaml multiqc_config.yaml snakemake_config.yaml","title":"2.1 Configs"},{"location":"iCLIP/preparing-files/#211-annotaiton-config-annotation_configtxt","text":"The annotation config dictates the type and location of annotaiton files to use for each species (hg38 and mm10). The file must include the following headers: type AnnoType hg38_options hg38_selection hg38_Custom mm10_options mm10_selection mm10_Custom description rmsk_flag notes Status","title":"2.1.1 Annotaiton Config (annotation_config.txt)"},{"location":"iCLIP/preparing-files/#212-cluster-config-cluster_configyml","text":"The cluster configuration file dictates the resouces to be used during submission to Biowulf HPC. There are two differnt ways to control these parameters - first, to control the default settings, and second, to create or edit individual rules. These parameters should be edited with caution, after significant testing.","title":"2.1.2 Cluster Config (cluster_config.yml)"},{"location":"iCLIP/preparing-files/#213-fastq-screen-config-fqscreen_rrna_configconf-and-fqscreen_species_configconf","text":"The FASTQ sceren configuration files dictates the parameters used for FASTQ Screen.","title":"2.1.3 FASTQ Screen Config (fqscreen_rrna_config.conf and fqscreen_species_config.conf)"},{"location":"iCLIP/preparing-files/#214-index-config-index_configyaml","text":"The index config is used to dictate what versions of reference index is used for each species (mm10, hg38). The structure of annotation is as follows: - organism: - std: '/path/to/index/' - spliceaware: - valuebp1: '/path/to/index1/' - valuebp2: '/path/to/index2/'","title":"2.1.4 Index Config (index_config.yaml)"},{"location":"iCLIP/preparing-files/#215-multiqc-config-multiqc_configyaml","text":"The MultiQC screen configuration files control the parameters used for MultiQC.","title":"2.1.5 MultiQC Config (multiqc_config.yaml)"},{"location":"iCLIP/preparing-files/#216-snakemake-config-snakemake_configyaml","text":"There are several groups of parameters that are editable for the user to control the various aspects of the pipeline. These are : Folders and Paths These parameters will include the input and ouput files of the pipeline, as well as list all manifest names. User parameters These parameters will control the pipeline features. These include thresholds and whether to perform processes. STAR parameters These parameters will control the STAR parameters for alignment. Modules, container parameters These parameters will control the version of tools used in the pipeline.","title":"2.1.6 Snakemake Config (snakemake_config.yaml)"},{"location":"iCLIP/preparing-files/#22-preparing-manifests","text":"There are three manifests, two of which are required for all pipeliens and one that is only required if running a differential expression method. These files describe information on the samples and desired contrasts. The paths of these files are defined in the snakemake_config.yaml file. These files are: multiplexManifest sampleManifest contrastManifest","title":"2.2 Preparing Manifests"},{"location":"iCLIP/preparing-files/#221-multiplex-manifest-required","text":"This manifest will include information to map fastq files to their multiple sample ID. It includes the following column headers: file_name: the full file name of the multiplexed sample, which must be unique; example: 'test_1.fastq.gz' multiplex: the multiplexID associated the fastq file, which must be unique. These names must match the multiplex column of the sampleManifest. example: 'test_1' An example multplex_manifest.tsv file: file_name,multiplex test_1.fastq.gz,test_1 test_2.fastq.gz,test_2","title":"2.2.1 Multiplex Manifest (REQUIRED)"},{"location":"iCLIP/preparing-files/#222-samples-manifest-required","text":"This manifest will include information to sample level information. It includes the following column headers: multiplex: the multiplexID associated with the fasta file, and will not be unique. These names must match the multiplex column of the multiplex_manifest.tsv file. example: 'SIM_iCLIP_S1' sample: the final sample name; this column must be unique. example: 'Ro_Clip' barcode: the barcode to identify multiplexed sample; this must be unique per each multiplex sample name but can repeat between multiplexid's. example: 'NNNTGGCNN' adaptor: the adaptor sequence, to be removed from sample; this may or may not be unique. example: 'AGATCGGAAGAGCGGTTCAG' group: groupings for samples, may or may not be unique values. example: 'CNTRL' An example sampleManifest file with multiplexing of one sample. Notice that the multiplexID test_1 is repeated, as Ro_Clip and Control_Clip are both found in the same fastq file, whereas test_2 is not multiplexed: multiplex,sample,group,barcode,adaptor test_1,Ro_Clip,CLIP,NNNTGGCNN,AGATCGGAAGAGCGGTTCAG test_1,Control_Clip,CNTRL,NNNCGGANN,AGATCGGAAGAGCGGTTCAG test_2,Ro_Clip2,CLIP,NNNCGTANN,AGATCGGAAGAGCGGTTCAG","title":"2.2.2 Samples Manifest (REQUIRED)"},{"location":"iCLIP/preparing-files/#223-contrast-manifest-required-with-de_method-of-manorm-or-diffbind","text":"This manifest will include sample or group information to performed differential expresison comparisons (MANORM or DIFFBIND). The column requirements differ by DE method. - if MANORM: - sample: the sample name, identified in the samplesManifest [sample] column, of the sample to compare. example: 'Ro_Clip' - background: the background sample name, identified in the samplesManifest [sample] column, of the background to remove. example: 'Control_Clip' - if DIFFBIND: - sample: the sample group, identified in the samplesManifest [group] column, of the sample group to compare. example: 'CLIP' will include samples 'Ro_Clip' and 'Ro_Clip2' - background: the background group name, identified in the samplesManifest [group] column, of the background group to remove. example: 'CNTRL' will include sample 'Control_Clip' An example contrastManifest file for MANORM: sample,background Ro_Clip,Control_Clip An example contrastManifest file for DIFFBIND: group,background CLIP,CNTRL","title":"2.2.3 Contrast Manifest (REQUIRED with DE_Method of MANORM or DIFFBIND)"},{"location":"iCLIP/run/","text":"3. Running the Pipeline \u00b6 3.1 Pipeline Overview \u00b6 The Snakemake workflow has a multiple options: Usage: /data/RBL_NCI/Pipelines/iCLIP/[version number]/run_snakemake.sh -p pipeline -p options: initialize, dry-run, cluster, local, unlock, git, DAG, report, check Usage: -o output_dir -o path to output directory 3.2 Commands explained \u00b6 The following explains each of the command options: Preparation Commands initialize (REQUIRED): This must be performed before any Snakemake run (dry, local, cluster) can be performed. This will copy the necessary config, manifest and Snakefiles needed to run the pipeline to the provided output directory. dry-run (OPTIONAL): This is an optional step, to be performed before any Snakemake run (local, cluster). This will check for errors within the pipeline, and ensure that you have read/write access to the files needed to run the full pipeline. Processing Commands local - This will run the pipeline on a local node. NOTE: This should only be performed on an interactive node. cluster - This will submit a master job to the cluster, and subsequent sub-jobs as needed to complete the workflow. An email will be sent when the pipeline begins, if there are any errors, and when it completes. Other Commands (All optional) unlock: This will unlock the pipeline if an error caused it to stop in the middle of a run. git: This is only utilized for GITHUB Actions testing. DAG: This will produce a DAG of the workflow and dependencies, saved to the /output/dir/log directory report: This will produce a report generated from the snakemake statistics produced by your pipeline, saved to the /output/dir/log directory. check: This will check for errors in the rules surrounding input manifests. If there are errors they will be printed to the command line and to the output error file. To run any of these commands, follow the the syntax: sh run_snakemake.sh -p COMMAND -o /path/to/output/dir 3.3 Typical Workflow \u00b6 A typical command workflow, running on the cluser, is as follows: initialize dry-run cluster","title":"3. Running the Pipeline"},{"location":"iCLIP/run/#3-running-the-pipeline","text":"","title":"3. Running the Pipeline"},{"location":"iCLIP/run/#31-pipeline-overview","text":"The Snakemake workflow has a multiple options: Usage: /data/RBL_NCI/Pipelines/iCLIP/[version number]/run_snakemake.sh -p pipeline -p options: initialize, dry-run, cluster, local, unlock, git, DAG, report, check Usage: -o output_dir -o path to output directory","title":"3.1 Pipeline Overview"},{"location":"iCLIP/run/#32-commands-explained","text":"The following explains each of the command options: Preparation Commands initialize (REQUIRED): This must be performed before any Snakemake run (dry, local, cluster) can be performed. This will copy the necessary config, manifest and Snakefiles needed to run the pipeline to the provided output directory. dry-run (OPTIONAL): This is an optional step, to be performed before any Snakemake run (local, cluster). This will check for errors within the pipeline, and ensure that you have read/write access to the files needed to run the full pipeline. Processing Commands local - This will run the pipeline on a local node. NOTE: This should only be performed on an interactive node. cluster - This will submit a master job to the cluster, and subsequent sub-jobs as needed to complete the workflow. An email will be sent when the pipeline begins, if there are any errors, and when it completes. Other Commands (All optional) unlock: This will unlock the pipeline if an error caused it to stop in the middle of a run. git: This is only utilized for GITHUB Actions testing. DAG: This will produce a DAG of the workflow and dependencies, saved to the /output/dir/log directory report: This will produce a report generated from the snakemake statistics produced by your pipeline, saved to the /output/dir/log directory. check: This will check for errors in the rules surrounding input manifests. If there are errors they will be printed to the command line and to the output error file. To run any of these commands, follow the the syntax: sh run_snakemake.sh -p COMMAND -o /path/to/output/dir","title":"3.2 Commands explained"},{"location":"iCLIP/run/#33-typical-workflow","text":"A typical command workflow, running on the cluser, is as follows: initialize dry-run cluster","title":"3.3 Typical Workflow"},{"location":"iCLIP/test/","text":"1. Pipeline Tutorial \u00b6 Welcome to the iCLIP Pipeline Tutorial! 1.1 Getting Started \u00b6 Review the information on the Getting Started for a complete overview the pipeline. The tutorial below will use test data available on NIH Biowulf HPC only. A. Change working directory to the iCLIP repository cd /data/RBL_NCI/Pipelines/iCLIP/[version number] B. Initialize Pipeline sh run_snakemake.sh -p initialize -o /path/to/output/dir 1.2 Prepare the test set \u00b6 A. Four different test data sets are available, depending on the need. These include: - test_1: Single test (multiplex_flag=\"N\", splice_aware=\"N\", DE_method=\"none\") - test_2: Multiplexed test (multiplex_flag=\"Y\", splice_aware=\"Y\", DE_method=\"none\") - test_3: MANORM test (multiplex_flag=\"N\", splice_aware=\"Y\", DE_method=\"MANORM\") - test_4: DIFFBIND test (multiplex_flag=\"N\", splice_aware=\"Y\", DE_method=\"DIFFBIND\") B. Pull the test data to your output directory # example sh /data/CCBR_Pipeliner/iCLIP/test/run_test.sh -t TESTNAME -o /path/to/output/dir # example running test_3: sh /data/CCBR_Pipeliner/iCLIP/test/run_test.sh -t test_3 -o /path/to/output/dir -s /data/RBL_NCI/Pipelines/iCLIP/[version number] 1.3 Complete dry-run \u00b6 A. Complete a dry-run and review output sh run_snakemake.sh -p dry -o /path/to/output/dir/ Ensure that an expected output is displayed. An expected output for test_3 is as follows: job count min threads max threads ---------------------- ------- ------------- ------------- MANORM_RMD 2 2 2 MANORM_analysis 4 4 4 MANORM_beds 4 4 4 MANORM_post_processing 2 2 2 all 1 1 1 annotation_report 4 1 1 bgzip_beds 4 4 4 create_beds_safs 4 8 8 dedup 4 8 8 feature_counts 4 8 8 index_stats 4 8 8 multiqc 1 1 1 nondemux 4 1 1 peak_ExonIntron 4 32 32 peak_RMSK 8 32 32 peak_Transcripts 8 32 32 peak_junctions 4 32 32 peak_process 4 32 32 project_annotations 1 1 1 qc_fastq 4 1 1 qc_screen_validator 4 32 32 qc_troubleshoot 1 1 1 rename_fastqs 1 1 1 star 4 32 32 total 85 1 32 1.4 Run the pipeline \u00b6 Execute pipeline on the cluster OR locally #submit to the cluster (recommended) sh run_snakemake.sh -p cluster -o /path/to/output/dir/ 1.5 Review outputs \u00b6 Review the expected outputs on the Output page. If there are errors, review and performing stesp described on the Troubleshooting page as needed.","title":"Running Example Data"},{"location":"iCLIP/test/#1-pipeline-tutorial","text":"Welcome to the iCLIP Pipeline Tutorial!","title":"1. Pipeline Tutorial"},{"location":"iCLIP/test/#11-getting-started","text":"Review the information on the Getting Started for a complete overview the pipeline. The tutorial below will use test data available on NIH Biowulf HPC only. A. Change working directory to the iCLIP repository cd /data/RBL_NCI/Pipelines/iCLIP/[version number] B. Initialize Pipeline sh run_snakemake.sh -p initialize -o /path/to/output/dir","title":"1.1 Getting Started"},{"location":"iCLIP/test/#12-prepare-the-test-set","text":"A. Four different test data sets are available, depending on the need. These include: - test_1: Single test (multiplex_flag=\"N\", splice_aware=\"N\", DE_method=\"none\") - test_2: Multiplexed test (multiplex_flag=\"Y\", splice_aware=\"Y\", DE_method=\"none\") - test_3: MANORM test (multiplex_flag=\"N\", splice_aware=\"Y\", DE_method=\"MANORM\") - test_4: DIFFBIND test (multiplex_flag=\"N\", splice_aware=\"Y\", DE_method=\"DIFFBIND\") B. Pull the test data to your output directory # example sh /data/CCBR_Pipeliner/iCLIP/test/run_test.sh -t TESTNAME -o /path/to/output/dir # example running test_3: sh /data/CCBR_Pipeliner/iCLIP/test/run_test.sh -t test_3 -o /path/to/output/dir -s /data/RBL_NCI/Pipelines/iCLIP/[version number]","title":"1.2 Prepare the test set"},{"location":"iCLIP/test/#13-complete-dry-run","text":"A. Complete a dry-run and review output sh run_snakemake.sh -p dry -o /path/to/output/dir/ Ensure that an expected output is displayed. An expected output for test_3 is as follows: job count min threads max threads ---------------------- ------- ------------- ------------- MANORM_RMD 2 2 2 MANORM_analysis 4 4 4 MANORM_beds 4 4 4 MANORM_post_processing 2 2 2 all 1 1 1 annotation_report 4 1 1 bgzip_beds 4 4 4 create_beds_safs 4 8 8 dedup 4 8 8 feature_counts 4 8 8 index_stats 4 8 8 multiqc 1 1 1 nondemux 4 1 1 peak_ExonIntron 4 32 32 peak_RMSK 8 32 32 peak_Transcripts 8 32 32 peak_junctions 4 32 32 peak_process 4 32 32 project_annotations 1 1 1 qc_fastq 4 1 1 qc_screen_validator 4 32 32 qc_troubleshoot 1 1 1 rename_fastqs 1 1 1 star 4 32 32 total 85 1 32","title":"1.3 Complete dry-run"},{"location":"iCLIP/test/#14-run-the-pipeline","text":"Execute pipeline on the cluster OR locally #submit to the cluster (recommended) sh run_snakemake.sh -p cluster -o /path/to/output/dir/","title":"1.4 Run the pipeline"},{"location":"iCLIP/test/#15-review-outputs","text":"Review the expected outputs on the Output page. If there are errors, review and performing stesp described on the Troubleshooting page as needed.","title":"1.5 Review outputs"},{"location":"iCLIP/troubleshooting/","text":"2. Troubleshooting \u00b6 Recommended steps to troubleshoot the pipeline 2.1 Email \u00b6 Check your email for an email regarding pipeline failure. You will receive an email from slurm@biowulf.nih.gov with the subject: Slurm Job_id=[#] Name=iCLIP Failed, Run time [time], FAILED, ExitCode 1 2.2 Error Report \u00b6 Run the error report script cd /[output_dir]/log/[time_of_run] sh 00_create_error_report.sh cat error.log Review the report for the rules that erred, and the sample information. An example report is listed below: The following error(s) were found in rules: ********************************************* Error in rule rule1: Error in rule rule2: Error in rule rule3: The following samples are affected by memory and must be deleted: rule1.[sbatchid].sp=[sample_name].err:[E::hts_open_format] Disc quota exceeded The following samples are affected by missing input files/output dir and should be reviewed: rule2.[sbatchid].sp=[sample_name].err:[E::hts_open_format] Failed to open file \"[file_name]\" : No such file or directory The following samples are affected by other error_rules and should be reviewed: rule3.[sbatchid].sp=[sample_name].err:[E::hts_open_format] TIMEOUT 2.3 Restart the run \u00b6 After addressing the issue, unlock the output directory, perform another dry-run and check the status of the pipeline, then resubmit to the cluster. #unlock dir sh run_snakemake.sh -p unlock -o /path/to/output/dir #perform dry-run sh run_snakemake.sh -p dry -o /path/to/output/dir #submit to cluster sh run_snakemake.sh -p cluster -o /path/to/output/dir","title":"Troubleshooting"},{"location":"iCLIP/troubleshooting/#2-troubleshooting","text":"Recommended steps to troubleshoot the pipeline","title":"2. Troubleshooting"},{"location":"iCLIP/troubleshooting/#21-email","text":"Check your email for an email regarding pipeline failure. You will receive an email from slurm@biowulf.nih.gov with the subject: Slurm Job_id=[#] Name=iCLIP Failed, Run time [time], FAILED, ExitCode 1","title":"2.1 Email"},{"location":"iCLIP/troubleshooting/#22-error-report","text":"Run the error report script cd /[output_dir]/log/[time_of_run] sh 00_create_error_report.sh cat error.log Review the report for the rules that erred, and the sample information. An example report is listed below: The following error(s) were found in rules: ********************************************* Error in rule rule1: Error in rule rule2: Error in rule rule3: The following samples are affected by memory and must be deleted: rule1.[sbatchid].sp=[sample_name].err:[E::hts_open_format] Disc quota exceeded The following samples are affected by missing input files/output dir and should be reviewed: rule2.[sbatchid].sp=[sample_name].err:[E::hts_open_format] Failed to open file \"[file_name]\" : No such file or directory The following samples are affected by other error_rules and should be reviewed: rule3.[sbatchid].sp=[sample_name].err:[E::hts_open_format] TIMEOUT","title":"2.2 Error Report"},{"location":"iCLIP/troubleshooting/#23-restart-the-run","text":"After addressing the issue, unlock the output directory, perform another dry-run and check the status of the pipeline, then resubmit to the cluster. #unlock dir sh run_snakemake.sh -p unlock -o /path/to/output/dir #perform dry-run sh run_snakemake.sh -p dry -o /path/to/output/dir #submit to cluster sh run_snakemake.sh -p cluster -o /path/to/output/dir","title":"2.3 Restart the run"}]}